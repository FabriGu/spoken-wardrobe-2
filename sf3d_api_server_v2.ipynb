{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SF3D API Server - JupyterHub (v2)\n",
    "\n",
    "This notebook runs a FastAPI server on the school GPU to generate 3D meshes using Stable Fast 3D.\n",
    "\n",
    "## ‚ö†Ô∏è IMPORTANT: Run cells in order from top to bottom!\n",
    "\n",
    "**Setup Steps:**\n",
    "1. Run Cell 1: Install dependencies (wait for completion)\n",
    "2. **RESTART KERNEL** (Kernel ‚Üí Restart)\n",
    "3. Run Cell 2: Import libraries\n",
    "4. Run Cell 3: Load SF3D model (takes 10-30 seconds first time)\n",
    "5. Run Cell 4: Define API endpoints\n",
    "6. Run Cell 5: Start server (keep running)\n",
    "7. Test from Mac: `python tests/sf3d_api_client.py <image_path>`\n",
    "\n",
    "**Server URL:** `http://itp-ml.itp.tsoa.nyu.edu:<PORT>/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Install Dependencies\n",
    "\n",
    "**Run this first, then RESTART KERNEL before continuing!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Install FastAPI and web server\n",
    "pip install --user fastapi uvicorn[standard] python-multipart\n",
    "\n",
    "# Install PyTorch with CUDA 11.8 (matching server)\n",
    "pip install --user torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Install 3D and image libraries\n",
    "pip install --user trimesh pillow numpy\n",
    "\n",
    "# Install transformers for model loading\n",
    "pip install --user transformers accelerate\n",
    "\n",
    "# Install Stability AI's TripoSR (similar to SF3D, well-supported)\n",
    "pip install --user git+https://github.com/VAST-AI-Research/TripoSR.git\n",
    "\n",
    "echo \"\"\n",
    "echo \"‚úÖ Installation complete!\"\n",
    "echo \"\"\n",
    "echo \"‚ö†Ô∏è  IMPORTANT: Now go to Kernel ‚Üí Restart Kernel\"\n",
    "echo \"   Then run the remaining cells in order.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Import Libraries\n",
    "\n",
    "**After restarting kernel, run this cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from fastapi import FastAPI, File, UploadFile, Form, HTTPException\n",
    "from fastapi.responses import FileResponse, JSONResponse\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import uvicorn\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully\")\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: CUDA not available! Will use CPU (very slow)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Load TripoSR Model\n",
    "\n",
    "**This loads the 3D generation model (first time: 10-30 seconds)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load TripoSR model\n",
    "print(\"\\nLoading TripoSR model...\")\n",
    "print(\"(First time: downloads ~2GB model, may take 30 seconds)\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    from tsr.system import TSR\n",
    "    \n",
    "    model = TSR.from_pretrained(\n",
    "        \"stabilityai/TripoSR\",\n",
    "        config_name=\"config.yaml\",\n",
    "        weight_name=\"model.ckpt\",\n",
    "    )\n",
    "    model.renderer.set_chunk_size(8192)  # Optimize for GPU\n",
    "    model.to(device)\n",
    "    \n",
    "    print(f\"\\n‚úÖ TripoSR model loaded in {time.time() - start_time:.1f}s\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error loading TripoSR: {e}\")\n",
    "    print(\"\\nTrying alternative method...\")\n",
    "    \n",
    "    # Fallback: Manual implementation\n",
    "    import sys\n",
    "    sys.path.insert(0, '/home/jovyan/.local/lib/python3.10/site-packages')\n",
    "    \n",
    "    from tsr.system import TSR\n",
    "    model = TSR.from_pretrained(\"stabilityai/TripoSR\")\n",
    "    model.to(device)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Model loaded (fallback) in {time.time() - start_time:.1f}s\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(\"/tmp/sf3d_outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "print(f\"\\nOutput directory: {output_dir}\")\n",
    "print(\"\\n‚úÖ Ready to generate meshes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Define API Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FastAPI\n",
    "app = FastAPI(\n",
    "    title=\"TripoSR 3D Generation API\",\n",
    "    description=\"Generate 3D meshes from images using TripoSR\",\n",
    "    version=\"2.0.0\"\n",
    ")\n",
    "\n",
    "# Enable CORS\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\n",
    "        \"message\": \"TripoSR 3D Generation API\",\n",
    "        \"status\": \"running\",\n",
    "        \"device\": device,\n",
    "        \"model\": \"stabilityai/TripoSR\",\n",
    "        \"endpoints\": {\n",
    "            \"/generate\": \"POST - Generate 3D mesh from image\",\n",
    "            \"/health\": \"GET - Health check\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health():\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"device\": device,\n",
    "        \"cuda_available\": torch.cuda.is_available(),\n",
    "        \"model_loaded\": model is not None\n",
    "    }\n",
    "\n",
    "@app.post(\"/generate\")\n",
    "async def generate_mesh(\n",
    "    file: UploadFile = File(...),\n",
    "    texture_resolution: int = Form(1024),\n",
    "    remesh_option: str = Form(\"none\"),\n",
    "    foreground_ratio: float = Form(0.85)\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate 3D mesh from uploaded image.\n",
    "    \n",
    "    Parameters:\n",
    "    - file: Image file (PNG, JPG)\n",
    "    - texture_resolution: Not used (TripoSR auto)\n",
    "    - remesh_option: Not used (TripoSR auto)\n",
    "    - foreground_ratio: Not used (TripoSR auto)\n",
    "    \n",
    "    Returns:\n",
    "    - GLB file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read and validate image\n",
    "        image_data = await file.read()\n",
    "        image = Image.open(io.BytesIO(image_data))\n",
    "        \n",
    "        # Convert to RGB if needed\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        print(f\"\\n[{time.strftime('%H:%M:%S')}] Received image: {image.size}\")\n",
    "        \n",
    "        # Generate mesh\n",
    "        start_time = time.time()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # TripoSR inference\n",
    "            scene_codes = model([image], device=device)\n",
    "            \n",
    "            # Extract mesh\n",
    "            meshes = model.extract_mesh(scene_codes)\n",
    "            mesh = meshes[0]\n",
    "        \n",
    "        generation_time = time.time() - start_time\n",
    "        print(f\"[{time.strftime('%H:%M:%S')}] Generation completed in {generation_time:.2f}s\")\n",
    "        \n",
    "        # Save mesh to temporary file\n",
    "        timestamp = int(time.time() * 1000)\n",
    "        output_path = output_dir / f\"mesh_{timestamp}.glb\"\n",
    "        \n",
    "        # Export as GLB\n",
    "        mesh.export(str(output_path), file_type='glb')\n",
    "        \n",
    "        file_size = output_path.stat().st_size\n",
    "        print(f\"[{time.strftime('%H:%M:%S')}] Saved: {output_path.name} ({file_size / 1024:.1f} KB)\\n\")\n",
    "        \n",
    "        # Return file\n",
    "        return FileResponse(\n",
    "            path=output_path,\n",
    "            media_type=\"model/gltf-binary\",\n",
    "            filename=f\"mesh_{timestamp}.glb\",\n",
    "            headers={\n",
    "                \"X-Generation-Time\": str(generation_time),\n",
    "                \"X-File-Size\": str(file_size)\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error generating mesh: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "print(\"\\n‚úÖ API endpoints defined\")\n",
    "print(\"   Ready to start server!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Start Server\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT:**\n",
    "- This cell will run indefinitely\n",
    "- Keep the notebook open\n",
    "- Press ‚ñ† (stop) button to stop server\n",
    "- Check if port 8765 is available (change if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure server\n",
    "PORT = 8765  # Change this if port is already in use (try 8766, 8767, etc.)\n",
    "HOST = \"0.0.0.0\"  # Listen on all interfaces\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ Starting TripoSR API Server\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Server URL: http://itp-ml.itp.tsoa.nyu.edu:{PORT}/\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Model: TripoSR\")\n",
    "print(f\"\")\n",
    "print(\"Available endpoints:\")\n",
    "print(f\"  GET  http://itp-ml.itp.tsoa.nyu.edu:{PORT}/           - API info\")\n",
    "print(f\"  GET  http://itp-ml.itp.tsoa.nyu.edu:{PORT}/health     - Health check\")\n",
    "print(f\"  POST http://itp-ml.itp.tsoa.nyu.edu:{PORT}/generate   - Generate 3D mesh\")\n",
    "print(f\"\")\n",
    "print(\"To test from your Mac:\")\n",
    "print(f\"  python tests/sf3d_api_client.py <image> --server http://itp-ml.itp.tsoa.nyu.edu:{PORT}\")\n",
    "print(\"\")\n",
    "print(\"Or test with curl:\")\n",
    "print(f\"  curl http://itp-ml.itp.tsoa.nyu.edu:{PORT}/health\")\n",
    "print(\"=\"*70)\n",
    "print(\"\")\n",
    "print(\"‚ö†Ô∏è  KEEP THIS CELL RUNNING - Server logs will appear below\")\n",
    "print(\"\")\n",
    "\n",
    "# Run server\n",
    "try:\n",
    "    uvicorn.run(app, host=HOST, port=PORT, log_level=\"info\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\n‚úÖ Server stopped\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n\\n‚ùå Server error: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"  - If port is in use, change PORT above and re-run this cell\")\n",
    "    print(\"  - If permission denied, try PORT > 1024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### \"Port already in use\"\n",
    "- Change `PORT = 8765` to another number (8766, 8767, etc.)\n",
    "- Re-run Cell 5 only\n",
    "\n",
    "### \"CUDA out of memory\"\n",
    "- Someone else may be using the GPU\n",
    "- Try again later or use smaller images\n",
    "\n",
    "### \"Module not found\" errors\n",
    "- Go back to Cell 1\n",
    "- Re-run installation\n",
    "- RESTART KERNEL (Kernel ‚Üí Restart)\n",
    "- Run cells 2-5 again\n",
    "\n",
    "### Server not accessible from Mac\n",
    "- Make sure you're on NYU network/VPN\n",
    "- Check server URL matches what's printed above\n",
    "- Test with curl first: `curl http://itp-ml.itp.tsoa.nyu.edu:8765/health`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
