"""
PHASE 4: AI CLOTHING GENERATION WITH STABLE DIFFUSION
======================================================

PURPOSE: Take spoken words and generate custom clothing images using
Stable Diffusion AI.

LEARNING RESOURCES:
- Stable Diffusion: https://huggingface.co/blog/stable_diffusion
- Diffusers Library: https://huggingface.co/docs/diffusers/index
- PyTorch MPS: https://pytorch.org/docs/stable/notes/mps.html
- Prompt Engineering: https://huggingface.co/docs/diffusers/using-diffusers/write_prompts

WHAT YOU'RE BUILDING:
A system that takes text (e.g., "flames", "roses", "thorns") and generates
a custom clothing design incorporating that concept. The clothing has a
white background for easy removal and overlay.
"""

import torch
from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler
from PIL import Image
import numpy as np
import time
import os
from rembg import remove  # For background removal


class ClothingGenerator:
    """
    This class handles AI-powered clothing generation using Stable Diffusion.
    
    HOW IT WORKS:
    1. Takes text prompt from speech
    2. Expands it into a detailed prompt for better results
    3. Generates clothing image using Stable Diffusion
    4. Removes background to get transparent PNG
    5. Returns clothing ready to overlay on body
    """
    
    def __init__(self, model_id="runwayml/stable-diffusion-v1-5", cache_dir="./models"):
        """
        Initialize the clothing generation system.
        
        PARAMETERS:
        - model_id: Which Stable Diffusion model to use
                   "runwayml/stable-diffusion-v1-5" is the standard SD 1.5
        - cache_dir: Where to store downloaded model weights
        
        MODEL DOWNLOAD SIZE: ~4GB (only downloads once)
        """
        
        self.model_id = model_id
        self.cache_dir = cache_dir
        
        # Create cache directory if it doesn't exist
        os.makedirs(cache_dir, exist_ok=True)
        
        # Will be initialized when we load the model
        self.pipeline = None
        self.device = None
        
        # Generation parameters (can be tuned)
        self.num_inference_steps = 30  # More steps = higher quality but slower
        self.guidance_scale = 7.5  # How closely to follow the prompt (1-20)
        self.image_size = 512  # Output size (512x512 is standard for SD 1.5)
        
        # Cache for generated images (avoid regenerating same thing)
        self.generation_cache = {}
        
        print("ClothingGenerator initialized")
        print(f"Model: {model_id}")
        print(f"Cache directory: {cache_dir}")
    
    
    def load_model(self):
        """
        Load the Stable Diffusion model.
        
        WARNING: First run will download ~4GB of model weights!
        Subsequent runs load from cache and are much faster.
        
        This takes 1-2 minutes on first run, ~10 seconds after that.
        """
        
        print("\nLoading Stable Diffusion model...")
        print("First time will download ~4GB (be patient!)")
        
        start_time = time.time()
        
        # Determine which device to use
        if torch.backends.mps.is_available():
            self.device = "mps"  # Mac GPU
            print("Using Mac GPU (MPS) acceleration")
        elif torch.cuda.is_available():
            self.device = "cuda"  # Nvidia GPU
            print("Using NVIDIA GPU (CUDA) acceleration")
        else:
            self.device = "cpu"
            print("Using CPU (will be slow!)")
        
        # Load the pipeline
        # The pipeline bundles together: tokenizer, text encoder, UNet, VAE, scheduler
        self.pipeline = StableDiffusionPipeline.from_pretrained(
            self.model_id,
            torch_dtype=torch.float16 if self.device != "cpu" else torch.float32,
            cache_dir=self.cache_dir
        )
        
        # Use DPM++ scheduler for better quality in fewer steps
        self.pipeline.scheduler = DPMSolverMultistepScheduler.from_config(
            self.pipeline.scheduler.config
        )
        
        # Move to device
        self.pipeline = self.pipeline.to(self.device)
        
        # Enable attention slicing to reduce memory usage
        self.pipeline.enable_attention_slicing()
        
        # On Mac, reduce memory fragmentation
        if self.device == "mps":
            self.pipeline.enable_attention_slicing("max")
        
        load_time = time.time() - start_time
        print(f"Model loaded in {load_time:.1f} seconds!")
        print(f"Generation will take ~{self.num_inference_steps} seconds per image")
    
    
    def create_prompt(self, user_input, clothing_type="dress"):
        """
        Transform simple user input into a detailed Stable Diffusion prompt.
        
        PROMPT ENGINEERING IS CRUCIAL!
        A good prompt makes the difference between amazing and terrible results.
        
        PARAMETERS:
        - user_input: What the user said (e.g., "flames", "roses and thorns")
        - clothing_type: Type of garment ("dress", "suit", "cape", "jacket")
        
        RETURNS:
        - Detailed prompt for Stable Diffusion
        - Negative prompt (what to avoid)
        
        EXAMPLE:
        Input: "flames"
        Output: "haute couture fashion dress made of realistic flames, 
                elegant design, professional fashion photography, 
                white background, centered, highly detailed, 4k"
        """
        
        # Detect if user mentioned specific clothing type
        user_lower = user_input.lower()
        if any(word in user_lower for word in ["dress", "gown"]):
            clothing_type = "dress"
        elif any(word in user_lower for word in ["suit", "jacket", "blazer"]):
            clothing_type = "suit"
        elif any(word in user_lower for word in ["cape", "cloak"]):
            clothing_type = "cape"
        elif any(word in user_lower for word in ["shirt", "top"]):
            clothing_type = "shirt"
        
        # Build the prompt
        # These keywords help SD generate better fashion images
        prompt = f"""haute couture fashion {clothing_type} made of {user_input},
        elegant and artistic design, professional fashion photography,
        studio lighting, white background, centered on white backdrop,
        highly detailed, 4k, masterpiece, trending on artstation"""
        
        # Negative prompt - what we DON'T want
        # These help avoid common SD problems
        negative_prompt = """low quality, blurry, distorted, deformed, ugly,
        bad anatomy, extra limbs, text, watermark, signature,
        person wearing it, model, body, face,
        busy background, cluttered, realistic photo of person"""
        
        return prompt, negative_prompt
    
    
    def generate(self, prompt, negative_prompt=None, seed=None):
        """
        Generate a clothing image using Stable Diffusion.
        
        PARAMETERS:
        - prompt: Detailed description of clothing to generate
        - negative_prompt: What to avoid
        - seed: Random seed for reproducibility (None = random)
        
        RETURNS:
        - PIL Image of generated clothing
        """
        
        if self.pipeline is None:
            raise Exception("Model not loaded! Call load_model() first.")
        
        print(f"\nGenerating clothing...")
        print(f"Prompt: {prompt[:100]}...")
        
        start_time = time.time()
        
        # Set random seed if provided (for reproducible results)
        if seed is not None:
            generator = torch.Generator(device=self.device).manual_seed(seed)
        else:
            generator = None
        
        # Generate the image
        # This is where the magic happens!
        with torch.no_grad():  # Don't compute gradients (we're not training)
            result = self.pipeline(
                prompt=prompt,
                negative_prompt=negative_prompt,
                num_inference_steps=self.num_inference_steps,
                guidance_scale=self.guidance_scale,
                height=self.image_size,
                width=self.image_size,
                generator=generator
            )
        
        # Extract the image from the result
        image = result.images[0]
        
        gen_time = time.time() - start_time
        print(f"Generation complete in {gen_time:.1f} seconds!")
        
        return image
    
    
    def remove_background(self, image):
        """
        Remove the background from the generated clothing image.
        
        This uses the rembg library which runs a neural network (U2-Net)
        to detect and remove backgrounds.
        
        PARAMETERS:
        - image: PIL Image with clothing on white background
        
        RETURNS:
        - PIL Image with transparent background (RGBA mode)
        """
        
        print("Removing background...")
        start_time = time.time()
        
        # Convert PIL Image to bytes
        # rembg can work directly with PIL Images
        output_image = remove(image)
        
        # Ensure it's in RGBA mode (with alpha channel for transparency)
        if output_image.mode != 'RGBA':
            output_image = output_image.convert('RGBA')
        
        bg_time = time.time() - start_time
        print(f"Background removed in {bg_time:.1f} seconds!")
        
        return output_image
    
    
    def generate_clothing_from_text(self, text, remove_bg=True, use_cache=True):
        """
        Main function: text in, clothing image out!
        
        This is the high-level function you'll call from your main app.
        It handles the full pipeline: prompt creation → generation → bg removal
        
        PARAMETERS:
        - text: User's spoken text
        - remove_bg: Whether to remove background (should be True)
        - use_cache: Whether to check cache for this text
        
        RETURNS:
        - PIL Image with transparent background
        - None if generation failed
        """
        
        # Check cache first
        if use_cache and text in self.generation_cache:
            print(f"Using cached result for '{text}'")
            return self.generation_cache[text]
        
        try:
            # Step 1: Create detailed prompt
            prompt, negative_prompt = self.create_prompt(text)
            
            # Step 2: Generate with Stable Diffusion
            clothing_image = self.generate(prompt, negative_prompt)
            
            # Step 3: Remove background
            if remove_bg:
                clothing_image = self.remove_background(clothing_image)
            
            # Step 4: Cache the result
            if use_cache:
                self.generation_cache[text] = clothing_image
            
            return clothing_image
        
        except Exception as e:
            print(f"Error generating clothing: {e}")
            return None
    
    
    def save_image(self, image, filename="generated_clothing.png"):
        """
        Save a generated image to disk.
        
        Useful for debugging and building a library of generations.
        """
        
        os.makedirs("generated_images", exist_ok=True)
        filepath = os.path.join("generated_images", filename)
        
        image.save(filepath)
        print(f"Saved image to {filepath}")
        
        return filepath
    
    
    def clear_cache(self):
        """
        Clear the generation cache to free memory.
        """
        self.generation_cache.clear()
        print("Generation cache cleared")
    
    
    def cleanup(self):
        """
        Clean up resources.
        """
        if self.pipeline is not None:
            del self.pipeline
            self.pipeline = None
            
            # Clear CUDA cache if using GPU
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            print("ClothingGenerator cleaned up")


# ============================================================================
# USAGE EXAMPLE
# ============================================================================

def main():
    """
    Test the clothing generation system.
    """
    
    print("=" * 60)
    print("PHASE 4: AI CLOTHING GENERATION TEST")
    print("=" * 60)
    print("\nThis will generate clothing images from text prompts.")
    print("First run will download ~4GB of model weights.")
    print("Be patient - this takes 1-2 minutes on first run!")
    print("=" * 60)
    
    # Initialize generator
    generator = ClothingGenerator()
    
    # Load the model
    try:
        generator.load_model()
    except Exception as e:
        print(f"\nError loading model: {e}")
        print("\nTROUBLESHOOTING:")
        print("1. Make sure you have enough disk space (~5GB)")
        print("2. Check your internet connection")
        print("3. Try again - sometimes downloads timeout")
        return
    
    # Test prompts
    test_prompts = [
        "flames",
        "roses and thorns",
        "made of tree bark",
        "cosmic stars and galaxies",
        "water droplets"
    ]
    
    print("\n" + "="*60)
    print("GENERATING TEST IMAGES")
    print("="*60)
    
    for i, prompt_text in enumerate(test_prompts):
        print(f"\n[{i+1}/{len(test_prompts)}] Generating: '{prompt_text}'")
        
        # Generate clothing
        clothing_image = generator.generate_clothing_from_text(prompt_text)
        
        if clothing_image is not None:
            # Save the image
            filename = f"{i+1}_{prompt_text.replace(' ', '_')}.png"
            generator.save_image(clothing_image, filename)
            
            print(f"✓ Success! Saved as {filename}")
        else:
            print(f"✗ Failed to generate")
        
        print("-" * 60)
    
    print("\n" + "="*60)
    print("TESTING COMPLETE!")
    print("="*60)
    print(f"\nCheck the 'generated_images' folder for results.")
    print("You should see 5 different clothing designs.")
    
    # Interactive mode
    print("\n" + "="*60)
    print("INTERACTIVE MODE")
    print("="*60)
    print("Enter text to generate clothing, or 'quit' to exit.")
    
    try:
        while True:
            user_input = input("\nEnter clothing concept: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'q']:
                break
            
            if not user_input:
                continue
            
            # Generate
            clothing = generator.generate_clothing_from_text(user_input)
            
            if clothing:
                # Save with timestamp
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                filename = f"custom_{timestamp}.png"
                generator.save_image(clothing, filename)
    
    except KeyboardInterrupt:
        print("\n\nInterrupted by user")
    
    finally:
        # Cleanup
        generator.cleanup()
        print("\nTest complete!")


if __name__ == "__main__":
    main()


# ============================================================================
# TESTING CHECKLIST
# ============================================================================
#
# [ ] Model downloads successfully (~4GB)
# [ ] Model loads without errors
# [ ] Test generations complete (5 images)
# [ ] Generated images look like clothing designs
# [ ] Backgrounds are properly removed (transparent)
# [ ] Images are saved to generated_images folder
# [ ] Interactive mode works
# [ ] Cache speeds up repeat generations
# [ ] Program exits cleanly
#
# COMMON ISSUES:
# - Out of memory: Reduce num_inference_steps to 20
# - Very slow generation: Normal on Mac CPU, expect 30-60 seconds
# - Poor quality: Increase guidance_scale to 9.0
# - Model download fails: Check internet, try again
# - Background not removed: Check rembg installation
#
# TUNING PARAMETERS:
# - num_inference_steps: 20-50 (higher = better quality, slower)
# - guidance_scale: 7.5 (how closely to follow prompt)
#   - Lower (5-7): More creative, unpredictable
#   - Higher (8-12): More literal, follows prompt closely
# - image_size: 512 is standard (higher uses more memory)
#
# PROMPT TIPS:
# - Be specific: "evening gown made of flames" vs just "flames"
# - Use art terms: "haute couture", "elegant", "detailed"
# - Specify style: "realistic", "artistic", "photographic"
# - Always include "white background" for easy removal
#
# NEXT STEPS:
# Phase 5 will take these generated clothing images and overlay them
# on the user's body using the tracking data from Phase 3!
# ============================================================================